{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers","metadata":{"execution":{"iopub.status.busy":"2023-05-31T03:04:58.693460Z","iopub.execute_input":"2023-05-31T03:04:58.693899Z","iopub.status.idle":"2023-05-31T03:05:10.482001Z","shell.execute_reply.started":"2023-05-31T03:04:58.693853Z","shell.execute_reply":"2023-05-31T03:05:10.480771Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.29.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.12.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.14.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (5.4.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.5.5)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.28.2)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.13.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.64.1)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.5.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.5.7)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"!pip install sentencepiece","metadata":{"execution":{"iopub.status.busy":"2023-05-31T03:05:10.485782Z","iopub.execute_input":"2023-05-31T03:05:10.486138Z","iopub.status.idle":"2023-05-31T03:05:21.441543Z","shell.execute_reply.started":"2023-05-31T03:05:10.486109Z","shell.execute_reply":"2023-05-31T03:05:21.440413Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (0.1.99)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport torch\nfrom sklearn.model_selection import train_test_split\nfrom transformers import XLNetTokenizer, XLNetForSequenceClassification, XLNetConfig, AdamW\nfrom torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler","metadata":{"execution":{"iopub.status.busy":"2023-05-31T03:05:21.443886Z","iopub.execute_input":"2023-05-31T03:05:21.444200Z","iopub.status.idle":"2023-05-31T03:05:34.251367Z","shell.execute_reply.started":"2023-05-31T03:05:21.444173Z","shell.execute_reply":"2023-05-31T03:05:34.250283Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"execution":{"iopub.status.busy":"2023-05-31T03:05:34.254391Z","iopub.execute_input":"2023-05-31T03:05:34.254738Z","iopub.status.idle":"2023-05-31T03:05:34.287230Z","shell.execute_reply.started":"2023-05-31T03:05:34.254704Z","shell.execute_reply":"2023-05-31T03:05:34.286081Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}]},{"cell_type":"code","source":"train_ori = pd.read_csv(\"/kaggle/input/jbnu-swuniv-ai/train_data.csv\")\ntest_ori = pd.read_csv(\"/kaggle/input/jbnu-swuniv-ai/test_data.csv\")\ntrain_desc = pd.read_csv(\"/kaggle/input/book-cover-prompt/merged_desc.csv\")\ntest_desc = pd.read_csv(\"/kaggle/input/book-cover-prompt/merged_test.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-05-31T03:05:34.289049Z","iopub.execute_input":"2023-05-31T03:05:34.289772Z","iopub.status.idle":"2023-05-31T03:05:35.363781Z","shell.execute_reply.started":"2023-05-31T03:05:34.289737Z","shell.execute_reply":"2023-05-31T03:05:35.362845Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"display(train_ori.head())\ndisplay(test_ori.head())\ndisplay(train_desc.head())\ndisplay(test_desc.head())","metadata":{"execution":{"iopub.status.busy":"2023-05-31T03:05:35.365739Z","iopub.execute_input":"2023-05-31T03:05:35.366113Z","iopub.status.idle":"2023-05-31T03:05:35.403783Z","shell.execute_reply.started":"2023-05-31T03:05:35.366077Z","shell.execute_reply":"2023-05-31T03:05:35.402781Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"   id        Filename                                              Title  \\\n0   0  1101903236.jpg  The Oz Family Kitchen: More Than 100 Simple an...   \n1   1  0804139857.jpg  Living with Intent: My Somewhat Messy Journey ...   \n2   2  0765334798.jpg                Redshirts: A Novel with Three Codas   \n3   3  0446310786.jpg                              To Kill a Mockingbird   \n4   4  1143002598.jpg  Canning and Preserving of Food Products with B...   \n\n                         label  \n0        Cookbooks, Food, Wine  \n1                    Self Help  \n2     Science Fiction, Fantasy  \n3  Mystery, Thriller, Suspense  \n4        Cookbooks, Food, Wine  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>Filename</th>\n      <th>Title</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1101903236.jpg</td>\n      <td>The Oz Family Kitchen: More Than 100 Simple an...</td>\n      <td>Cookbooks, Food, Wine</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0804139857.jpg</td>\n      <td>Living with Intent: My Somewhat Messy Journey ...</td>\n      <td>Self Help</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>0765334798.jpg</td>\n      <td>Redshirts: A Novel with Three Codas</td>\n      <td>Science Fiction, Fantasy</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>0446310786.jpg</td>\n      <td>To Kill a Mockingbird</td>\n      <td>Mystery, Thriller, Suspense</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>1143002598.jpg</td>\n      <td>Canning and Preserving of Food Products with B...</td>\n      <td>Cookbooks, Food, Wine</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"   id Filename                                              Title\n0   0    0.jpg  Elementary and Middle School Mathematics: Teac...\n1   1    1.jpg  Making Color Sing, 25th Anniversary Edition: P...\n2   2    2.jpg  Nursing Fundamentals DeMYSTiFieD: A Self-Teach...\n3   3    3.jpg  Allen and Greenough's New Latin Grammar (Dover...\n4   4    4.jpg                        The Encyclopedia of Fantasy","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>Filename</th>\n      <th>Title</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0.jpg</td>\n      <td>Elementary and Middle School Mathematics: Teac...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1.jpg</td>\n      <td>Making Color Sing, 25th Anniversary Edition: P...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>2.jpg</td>\n      <td>Nursing Fundamentals DeMYSTiFieD: A Self-Teach...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>3.jpg</td>\n      <td>Allen and Greenough's New Latin Grammar (Dover...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>4.jpg</td>\n      <td>The Encyclopedia of Fantasy</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"            image                                             prompt\n0  000713326X.jpg  a book cover of taking risks with watercolour,...\n1  0007853939.jpg  a book cover with a dragon and scroll on it, t...\n2  0020112602.jpg  a picture of a book cover with a drawing of a ...\n3  002079990X.jpg  a close up of a person writing on a piece of p...\n4  0027457702.jpg  a picture of a book cover with a man reading a...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image</th>\n      <th>prompt</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>000713326X.jpg</td>\n      <td>a book cover of taking risks with watercolour,...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0007853939.jpg</td>\n      <td>a book cover with a dragon and scroll on it, t...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0020112602.jpg</td>\n      <td>a picture of a book cover with a drawing of a ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>002079990X.jpg</td>\n      <td>a close up of a person writing on a piece of p...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0027457702.jpg</td>\n      <td>a picture of a book cover with a man reading a...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"       File                                             Prompt\n0     0.jpg  a close up of a book cover with a bunch of dif...\n1     1.jpg  making color sing practical lessons in color a...\n2    10.jpg  a book cover of the book tibet through the red...\n3   100.jpg  a book cover of computer hardware, software, a...\n4  1000.jpg  arafed image of a city with a river and a rive...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>File</th>\n      <th>Prompt</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.jpg</td>\n      <td>a close up of a book cover with a bunch of dif...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.jpg</td>\n      <td>making color sing practical lessons in color a...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>10.jpg</td>\n      <td>a book cover of the book tibet through the red...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>100.jpg</td>\n      <td>a book cover of computer hardware, software, a...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1000.jpg</td>\n      <td>arafed image of a city with a river and a rive...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train = pd.merge(train_ori, train_desc, left_on = 'Filename', right_on='image', how='inner')\ntrain = train[['id', 'Filename', 'Title', 'label', 'prompt']]\n\ntest = pd.merge(test_ori, test_desc, left_on = 'Filename', right_on='File', how='inner')\ntest = test[['id', 'Filename', 'Title', 'Prompt']]\ntest.columns = ['id', 'Filename', 'Title', 'prompt']","metadata":{"execution":{"iopub.status.busy":"2023-05-31T03:05:35.405179Z","iopub.execute_input":"2023-05-31T03:05:35.406082Z","iopub.status.idle":"2023-05-31T03:05:35.532833Z","shell.execute_reply.started":"2023-05-31T03:05:35.406046Z","shell.execute_reply":"2023-05-31T03:05:35.531788Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"torch.manual_seed(42)","metadata":{"execution":{"iopub.status.busy":"2023-05-31T03:05:35.534606Z","iopub.execute_input":"2023-05-31T03:05:35.535047Z","iopub.status.idle":"2023-05-31T03:05:35.546703Z","shell.execute_reply.started":"2023-05-31T03:05:35.535010Z","shell.execute_reply":"2023-05-31T03:05:35.545544Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"<torch._C.Generator at 0x7fed51e1fab0>"},"metadata":{}}]},{"cell_type":"code","source":"train, valid = train_test_split(train, test_size=0.1, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-05-31T03:05:35.548515Z","iopub.execute_input":"2023-05-31T03:05:35.548895Z","iopub.status.idle":"2023-05-31T03:05:35.574850Z","shell.execute_reply.started":"2023-05-31T03:05:35.548863Z","shell.execute_reply":"2023-05-31T03:05:35.573457Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased', do_lower_case=True)\n\nmax_length = 600 #입력 시퀀스 최대 길이 (조정 가능)\ntrain_input_texts = (train[\"Title\"] + \", \"+ train[\"prompt\"]).tolist()\nvalid_input_texts = (valid[\"Title\"] + \", \"+ valid[\"prompt\"]).tolist()\ntest_input_texts = (test[\"Title\"] + \", \"+ test[\"prompt\"]).tolist()\n\ntrain_encoded_inputs = tokenizer.batch_encode_plus(\n    train_input_texts,\n    max_length=max_length,\n    padding=\"longest\",\n    truncation=True,\n    return_tensors=\"pt\"\n)\nvalid_encoded_inputs = tokenizer.batch_encode_plus(\n    valid_input_texts,\n    max_length=max_length,\n    padding=\"longest\",\n    truncation=True,\n    return_tensors=\"pt\"\n)\n\ntest_encoded_inputs = tokenizer.batch_encode_plus(\n    test_input_texts,\n    max_length=max_length,\n    padding=\"longest\",\n    truncation=True,\n    return_tensors=\"pt\"\n)","metadata":{"execution":{"iopub.status.busy":"2023-05-31T03:05:35.579485Z","iopub.execute_input":"2023-05-31T03:05:35.579769Z","iopub.status.idle":"2023-05-31T03:07:46.387816Z","shell.execute_reply.started":"2023-05-31T03:05:35.579745Z","shell.execute_reply":"2023-05-31T03:07:46.386760Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)ve/main/spiece.model:   0%|          | 0.00/798k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"56fd634b073a487ea9897b988e244a4f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/760 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"68bdfa66cb954992842372750273541e"}},"metadata":{}}]},{"cell_type":"code","source":"train_input_ids = train_encoded_inputs[\"input_ids\"].to(device)\ntrain_attention_mask = train_encoded_inputs[\"attention_mask\"].to(device)\n\nlabel_mapping = {label: i for i, label in enumerate(train[\"label\"].unique())}\nnum_labels = len(label_mapping)\ntrain_labels = train[\"label\"].map(label_mapping).tolist()\ntrain_labels = torch.tensor(train_labels).to(device)\n\nvalid_input_ids = valid_encoded_inputs[\"input_ids\"].to(device)\nvalid_attention_mask = valid_encoded_inputs[\"attention_mask\"].to(device)\n\ntest_input_ids = test_encoded_inputs[\"input_ids\"].to(device)\ntest_attention_mask = test_encoded_inputs[\"attention_mask\"].to(device)","metadata":{"execution":{"iopub.status.busy":"2023-05-31T03:07:46.389571Z","iopub.execute_input":"2023-05-31T03:07:46.389968Z","iopub.status.idle":"2023-05-31T03:07:51.338700Z","shell.execute_reply.started":"2023-05-31T03:07:46.389931Z","shell.execute_reply":"2023-05-31T03:07:51.337752Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"model = XLNetForSequenceClassification.from_pretrained(\"xlnet-base-cased\", num_labels=num_labels).to(device)","metadata":{"execution":{"iopub.status.busy":"2023-05-31T03:07:51.340310Z","iopub.execute_input":"2023-05-31T03:07:51.340679Z","iopub.status.idle":"2023-05-31T03:08:19.713814Z","shell.execute_reply.started":"2023-05-31T03:07:51.340642Z","shell.execute_reply":"2023-05-31T03:08:19.712857Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading pytorch_model.bin:   0%|          | 0.00/467M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e80b21af54e432e8952ecda5ba6968b"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary.summary.weight', 'logits_proj.weight', 'sequence_summary.summary.bias', 'logits_proj.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"batch_size = 16\n\ntrain_data = torch.utils.data.TensorDataset(train_input_ids, train_attention_mask, train_labels)\ntrain_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n\nvalid_data = torch.utils.data.TensorDataset(valid_input_ids, valid_attention_mask)\nvalid_loader = torch.utils.data.DataLoader(valid_data, batch_size=batch_size, shuffle=True)\n\ntest_data = torch.utils.data.TensorDataset(test_input_ids, test_attention_mask)\ntest_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2023-05-31T03:08:19.715414Z","iopub.execute_input":"2023-05-31T03:08:19.715792Z","iopub.status.idle":"2023-05-31T03:08:19.724976Z","shell.execute_reply.started":"2023-05-31T03:08:19.715758Z","shell.execute_reply":"2023-05-31T03:08:19.722078Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# 최적화 설정 (선택 사항)\noptimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\nnum_epochs = 16","metadata":{"execution":{"iopub.status.busy":"2023-05-31T03:08:19.726535Z","iopub.execute_input":"2023-05-31T03:08:19.726892Z","iopub.status.idle":"2023-05-31T03:08:19.767204Z","shell.execute_reply.started":"2023-05-31T03:08:19.726861Z","shell.execute_reply":"2023-05-31T03:08:19.766121Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"import tqdm\n\nmodel.train()\n\nfrom sklearn.metrics import f1_score\n\nbest_f1_score = 0.0\npatience = 10\ncounter = 0\n\nfor epoch in tqdm.tqdm(range(num_epochs)):\n    train_loss = 0.0\n    predicted_labels = []\n    true_labels = []\n\n    for batch in train_loader:\n        input_ids, attention_mask, labels = batch\n        optimizer.zero_grad()\n\n        outputs = model(input_ids.to(device), attention_mask=attention_mask.to(device), labels=labels.to(device))\n        loss = outputs.loss\n        train_loss += loss.item()\n\n        loss.backward()\n        optimizer.step()\n\n        predicted = model(input_ids.to(device), attention_mask=attention_mask.to(device)).logits.argmax(dim=-1)\n        predicted_labels.extend(predicted.tolist())\n        true_labels.extend(labels.tolist())\n\n    avg_train_loss = train_loss / len(train_loader)\n    f1 = f1_score(true_labels, predicted_labels, average='macro')\n\n    print(f\"Epoch: {epoch+1}, Average Training Loss: {avg_train_loss}, F1 Score: {f1}\")\n\n    if f1 > best_f1_score:\n        best_f1_score = f1\n        counter = 0\n    else:\n        counter += 1\n        if counter >= patience:\n            print(\"Training stopped due to no improvement in F1 score.\")\n            break\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.eval()  # 모델을 평가 모드로 설정\n\nvalid_preds = []\n\nwith torch.no_grad():\n    for batch in tqdm.tqdm(valid_loader):\n        input_ids, attention_mask = batch  # 레이블은 필요하지 않으므로 \"_\"로 무시\n\n        # 모델에 입력 전달하여 예측 수행\n        outputs = model(input_ids.to(device), attention_mask=attention_mask.to(device))\n        logits = outputs.logits\n\n        # 예측된 장르 구분\n        preds = torch.argmax(logits, dim=1)\n        valid_preds.extend(preds.cpu().numpy())\n\n# 예측된 장르 결과를 원본 데이터프레임에 추가\nvalid['Predicted Genre'] = valid_preds\n\n# 결과 출력\nprint(valid[['Title', 'Predicted Genre']])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"valid_predicted_genres = [list(label_mapping.keys())[list(label_mapping.values()).index(pred)] for pred in valid_preds]\nvalid['Predicted Genre'] = valid_predicted_genres\nprint(valid[['Title', 'Predicted Genre']])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\nprint(classification_report(valid['label'],  valid['Predicted Genre']))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.eval()  # 모델을 평가 모드로 설정\n\ntest_preds = []\n\nwith torch.no_grad():\n    for batch in tqdm.tqdm(test_loader):\n        input_ids, attention_mask = batch  # 레이블은 필요하지 않으므로 \"_\"로 무시\n\n        # 모델에 입력 전달하여 예측 수행\n        outputs = model(input_ids.to(device), attention_mask=attention_mask.to(device))\n        logits = outputs.logits\n\n        # 예측된 장르 구분\n        preds = torch.argmax(logits, dim=1)\n        test_preds.extend(preds.cpu().numpy())\n\n# 예측된 장르 결과를 원본 데이터프레임에 추가\ntest['Predicted Genre'] = test_preds\n\n# 결과 출력\nprint(test[['Title', 'Predicted Genre']])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_predicted_genres = [list(label_mapping.keys())[list(label_mapping.values()).index(pred)] for pred in test_preds]\ntest['Predicted Genre'] = test_predicted_genres","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = pd.read_csv(\"/kaggle/input/jbnu-swuniv-ai/test_data.csv\")\ntest['label'] = test_predicted_genres\nprint(test[['Title', 'label']])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.to_csv('/kaggle/working/submission_prompt_10.csv', index=False, columns=['id', 'label'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}